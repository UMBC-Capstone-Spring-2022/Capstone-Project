# MURA Dataset: Multiclass Classification and Vision Transformers

Our aim is to classify x-ray images from the [MURA](https://stanfordmlgroup.github.io/competitions/mura/) dataset. 
There are 40,561 multi-view radiographic images of seven types that are elbow, finger, forearm, hand, humerus, 
shoulder, and wrist. These images are classified as normal or abnormal. We are implementing a vision transformer aritecture
base off of the paper [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
to see if a vision transformer architecture can beat the current state of the art CNN's accuracy. We will also
implement a multiclass approach to test if this can increase our accuracy also.

[Project Webpage](https://umbc-capstone-spring-2023.github.io/Capstone-Project/)

## Getting Started

You will need to request permission from [here](https://stanfordmlgroup.github.io/competitions/mura/) to be able to 
download the MURA dataset. You will then need to save it to your google drive. Then mount your google drive 
through the jupyter notebook to get it to run.

## Authors

* **Robert Reyes** - *Initial work* - (https://github.com/rreyes2155)
* **Nidhishree Sanam** - *Initial work* - (https://github.com/Sanamnidhishree)
* **Jeneva Williams-Blackwell** - *Initial work* - (https://github.com/jrwillia42)


